{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgZ00YY8bJH7",
        "outputId": "33bf253c-58f2-4451-e427-398bca7f07be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data collection for KAFKA Bug issues...\n",
            "Total 8500 issues found.\n",
            "Collected 100/8500 issues so far...\n",
            "Collected 200/8500 issues so far...\n",
            "Collected 300/8500 issues so far...\n",
            "Collected 400/8500 issues so far...\n",
            "Collected 500/8500 issues so far...\n",
            "Collected 600/8500 issues so far...\n",
            "Collected 700/8500 issues so far...\n",
            "Collected 800/8500 issues so far...\n",
            "Collected 900/8500 issues so far...\n",
            "Collected 1000/8500 issues so far...\n",
            "Collected 1100/8500 issues so far...\n",
            "Collected 1200/8500 issues so far...\n",
            "Collected 1300/8500 issues so far...\n",
            "Collected 1400/8500 issues so far...\n",
            "Collected 1500/8500 issues so far...\n",
            "Collected 1600/8500 issues so far...\n",
            "Collected 1700/8500 issues so far...\n",
            "Collected 1800/8500 issues so far...\n",
            "Collected 1900/8500 issues so far...\n",
            "Collected 2000/8500 issues so far...\n",
            "Collected 2100/8500 issues so far...\n",
            "Collected 2200/8500 issues so far...\n",
            "Collected 2300/8500 issues so far...\n",
            "Collected 2400/8500 issues so far...\n",
            "Collected 2500/8500 issues so far...\n",
            "Collected 2600/8500 issues so far...\n",
            "Collected 2700/8500 issues so far...\n",
            "Collected 2800/8500 issues so far...\n",
            "Collected 2900/8500 issues so far...\n",
            "Collected 3000/8500 issues so far...\n",
            "Collected 3100/8500 issues so far...\n",
            "Collected 3200/8500 issues so far...\n",
            "Collected 3300/8500 issues so far...\n",
            "Collected 3400/8500 issues so far...\n",
            "Collected 3500/8500 issues so far...\n",
            "Collected 3600/8500 issues so far...\n",
            "Collected 3700/8500 issues so far...\n",
            "Collected 3800/8500 issues so far...\n",
            "Collected 3900/8500 issues so far...\n",
            "Collected 4000/8500 issues so far...\n",
            "Collected 4100/8500 issues so far...\n",
            "Collected 4200/8500 issues so far...\n",
            "Collected 4300/8500 issues so far...\n",
            "Collected 4400/8500 issues so far...\n",
            "Collected 4500/8500 issues so far...\n",
            "Collected 4600/8500 issues so far...\n",
            "Collected 4700/8500 issues so far...\n",
            "Collected 4800/8500 issues so far...\n",
            "Collected 4900/8500 issues so far...\n",
            "Collected 5000/8500 issues so far...\n",
            "Collected 5100/8500 issues so far...\n",
            "Collected 5200/8500 issues so far...\n",
            "Collected 5300/8500 issues so far...\n",
            "Collected 5400/8500 issues so far...\n",
            "Collected 5500/8500 issues so far...\n",
            "Collected 5600/8500 issues so far...\n",
            "Collected 5700/8500 issues so far...\n",
            "Collected 5800/8500 issues so far...\n",
            "Collected 5900/8500 issues so far...\n",
            "Collected 6000/8500 issues so far...\n",
            "Collected 6100/8500 issues so far...\n",
            "Collected 6200/8500 issues so far...\n",
            "Collected 6300/8500 issues so far...\n",
            "Collected 6400/8500 issues so far...\n",
            "Collected 6500/8500 issues so far...\n",
            "Collected 6600/8500 issues so far...\n",
            "Collected 6700/8500 issues so far...\n",
            "Collected 6800/8500 issues so far...\n",
            "Collected 6900/8500 issues so far...\n",
            "Collected 7000/8500 issues so far...\n",
            "Collected 7100/8500 issues so far...\n",
            "Collected 7200/8500 issues so far...\n",
            "Collected 7300/8500 issues so far...\n",
            "Collected 7400/8500 issues so far...\n",
            "Collected 7500/8500 issues so far...\n",
            "Collected 7600/8500 issues so far...\n",
            "Collected 7700/8500 issues so far...\n",
            "Collected 7800/8500 issues so far...\n",
            "Collected 7900/8500 issues so far...\n",
            "Collected 8000/8500 issues so far...\n",
            "Collected 8100/8500 issues so far...\n",
            "Collected 8200/8500 issues so far...\n",
            "Collected 8300/8500 issues so far...\n",
            "Collected 8400/8500 issues so far...\n",
            "Collected 8500/8500 issues so far...\n",
            "All issues collected.\n",
            "\n",
            "Finished collecting 8500 issues.\n",
            "Created directory: data/raw/\n",
            "Raw data saved to data/raw/kafka_bug_reports_raw.csv\n",
            "\n",
            "--- Initial Data Exploration ---\n",
            "           key                                            summary  \\\n",
            "0  KAFKA-19522  LastKnownLeader should only be elected if it i...   \n",
            "1  KAFKA-19520               Bump Commons-Lang for CVE-2025-48924   \n",
            "2  KAFKA-19517  LoadSummary#numBytes include the size of all r...   \n",
            "3  KAFKA-19514    Deprecate and remove Properties from public API   \n",
            "4  KAFKA-19513  Flaky test: AclControlManagerTest.testDeleteEx...   \n",
            "\n",
            "                                         description    status resolution  \\\n",
            "0  In PartitionChangeBuilder, there is a bug that...      Open       None   \n",
            "1  Bump Commons-Lang for CVE-2025-48924\\r\\n\\r\\nÂ \\...  Resolved      Fixed   \n",
            "2  I think LoadSummary#numRecords should count al...      Open       None   \n",
            "3  Currently, Kafka clients (Producer, Consumer, ...      Open       None   \n",
            "4  [https://github.com/apache/kafka/actions/runs/...      Open       None   \n",
            "\n",
            "  issue_type priority         creator       assignee  \\\n",
            "0        Bug    Major      Calvin Liu     Calvin Liu   \n",
            "1        Bug    Major       Luke Chen  Dmitry Werner   \n",
            "2        Bug    Minor  Chia-Ping Tsai      Logan Zhu   \n",
            "3        Bug    Minor   Jhen-Yung Hsu  Jhen-Yung Hsu   \n",
            "4        Bug    Major   Apoorv Mittal           None   \n",
            "\n",
            "                     created_at                    updated_at  \\\n",
            "0  2025-07-19T05:35:03.000+0000  2025-07-19T10:40:28.000+0000   \n",
            "1  2025-07-18T12:40:15.000+0000  2025-07-19T07:08:16.000+0000   \n",
            "2  2025-07-17T17:50:52.000+0000  2025-07-18T00:25:36.000+0000   \n",
            "3  2025-07-16T10:31:43.000+0000  2025-07-17T15:44:57.000+0000   \n",
            "4  2025-07-16T08:54:52.000+0000  2025-07-16T08:54:52.000+0000   \n",
            "\n",
            "                    resolved_at     labels  \\\n",
            "0                          None              \n",
            "1  2025-07-19T07:08:16.000+0000              \n",
            "2                          None              \n",
            "3                          None  needs-kip   \n",
            "4                          None              \n",
            "\n",
            "                            components  fix_versions  comments_count  \n",
            "0                                              4.1.0               1  \n",
            "1                                       4.0.1, 4.1.0               0  \n",
            "2                                                                  0  \n",
            "3  admin, clients, consumer, producer                              0  \n",
            "4                                                                  0  \n",
            "\n",
            "--- Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8500 entries, 0 to 8499\n",
            "Data columns (total 16 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   key             8500 non-null   object\n",
            " 1   summary         8500 non-null   object\n",
            " 2   description     8318 non-null   object\n",
            " 3   status          8500 non-null   object\n",
            " 4   resolution      6345 non-null   object\n",
            " 5   issue_type      8500 non-null   object\n",
            " 6   priority        8500 non-null   object\n",
            " 7   creator         8434 non-null   object\n",
            " 8   assignee        5190 non-null   object\n",
            " 9   created_at      8500 non-null   object\n",
            " 10  updated_at      8500 non-null   object\n",
            " 11  resolved_at     6345 non-null   object\n",
            " 12  labels          8500 non-null   object\n",
            " 13  components      8500 non-null   object\n",
            " 14  fix_versions    8500 non-null   object\n",
            " 15  comments_count  8500 non-null   int64 \n",
            "dtypes: int64(1), object(15)\n",
            "memory usage: 1.0+ MB\n",
            "None\n",
            "\n",
            "--- Missing Values ---\n",
            "key                  0\n",
            "summary              0\n",
            "description        182\n",
            "status               0\n",
            "resolution        2155\n",
            "issue_type           0\n",
            "priority             0\n",
            "creator             66\n",
            "assignee          3310\n",
            "created_at           0\n",
            "updated_at           0\n",
            "resolved_at       2155\n",
            "labels               0\n",
            "components           0\n",
            "fix_versions         0\n",
            "comments_count       0\n",
            "dtype: int64\n",
            "\n",
            "--- Unique Issue Types (should be mostly 'Bug') ---\n",
            "issue_type\n",
            "Bug    8500\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Unique Statuses ---\n",
            "status\n",
            "Resolved           5846\n",
            "Open               1958\n",
            "Closed              499\n",
            "Patch Available      97\n",
            "In Progress          56\n",
            "Reopened             44\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import time # For pausing between requests to avoid hitting rate limits\n",
        "\n",
        "# --- Configuration ---\n",
        "JIRA_BASE_URL = \"https://issues.apache.org/jira/\"\n",
        "API_ENDPOINT = JIRA_BASE_URL + \"rest/api/2/search\"\n",
        "JIRA_PROJECT_KEY = \"KAFKA\"\n",
        "ISSUE_TYPE = \"Bug\"\n",
        "MAX_RESULTS_PER_PAGE = 100 # Maximum allowed by JIRA API usually\n",
        "\n",
        "# JQL query to fetch all bug issues for Kafka\n",
        "JQL_QUERY = f\"project = {JIRA_PROJECT_KEY} AND issuetype = {ISSUE_TYPE} ORDER BY created DESC\"\n",
        "\n",
        "# --- Authentication (if required, for public JIRA instances like Apache, it's often not for read-only) ---\n",
        "# For public Apache JIRA, you might not need authentication for basic reads.\n",
        "# If you hit rate limits or need more data, consider using a session or basic auth:\n",
        "# AUTH = ('your_username', 'your_password_or_token')\n",
        "# headers = {'Content-Type': 'application/json'} # Usually not needed for GET, but good practice\n",
        "# If using a token: headers = {\"Authorization\": \"Bearer YOUR_TOKEN\"}\n",
        "\n",
        "# --- Data Collection ---\n",
        "all_issues = []\n",
        "start_at = 0\n",
        "total_issues = None # Will be populated by the first API call\n",
        "\n",
        "print(f\"Starting data collection for {JIRA_PROJECT_KEY} {ISSUE_TYPE} issues...\")\n",
        "\n",
        "while True:\n",
        "    params = {\n",
        "        'jql': JQL_QUERY,\n",
        "        'startAt': start_at,\n",
        "        'maxResults': MAX_RESULTS_PER_PAGE,\n",
        "        'fields': 'summary,description,status,resolution,issuetype,priority,creator,assignee,created,updated,resolutiondate,labels,components,fixVersions,comment' # Request relevant fields\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(API_ENDPOINT, params=params) # Add auth=AUTH if using authentication\n",
        "        response.raise_for_status() # Raises HTTPError for bad responses (4xx or 5xx)\n",
        "        data = response.json()\n",
        "\n",
        "        if total_issues is None:\n",
        "            total_issues = data.get('total')\n",
        "            print(f\"Total {total_issues} issues found.\")\n",
        "\n",
        "        issues_on_page = data.get('issues', [])\n",
        "        if not issues_on_page:\n",
        "            print(\"No more issues found or end of pagination.\")\n",
        "            break # No more issues\n",
        "\n",
        "        all_issues.extend(issues_on_page)\n",
        "        print(f\"Collected {len(all_issues)}/{total_issues} issues so far...\")\n",
        "\n",
        "        start_at += len(issues_on_page)\n",
        "\n",
        "        # Implement a delay to be respectful of the API's rate limits\n",
        "        # For public JIRA, 1-2 seconds between requests is a good starting point.\n",
        "        time.sleep(1.5)\n",
        "\n",
        "        if start_at >= total_issues:\n",
        "            print(\"All issues collected.\")\n",
        "            break\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during API request: {e}\")\n",
        "        break\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON response: {e}\")\n",
        "        print(f\"Response content: {response.text}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nFinished collecting {len(all_issues)} issues.\")\n",
        "\n",
        "# --- Process Collected Data ---\n",
        "# Extract relevant fields into a list of dictionaries\n",
        "# --- Process Collected Data ---\n",
        "# Extract relevant fields into a list of dictionaries\n",
        "processed_issue_data = []\n",
        "for issue in all_issues:\n",
        "    fields = issue.get('fields', {})\n",
        "\n",
        "    creator_name = fields.get('creator', {}).get('displayName') if fields.get('creator') else None\n",
        "    assignee_name = fields.get('assignee', {}).get('displayName') if fields.get('assignee') else None\n",
        "\n",
        "    # Safely get resolution name (from previous fix)\n",
        "    resolution_data = fields.get('resolution')\n",
        "    resolution_name = resolution_data.get('name') if resolution_data else None\n",
        "\n",
        "    # --- FIX STARTS HERE (Labels and Components/FixVersions might follow similar pattern) ---\n",
        "    # For labels, it's more common for them to be a list of strings directly\n",
        "    # So, we can directly join them, ensuring to handle potential None if labels field itself is missing\n",
        "    labels_list = fields.get('labels', [])\n",
        "    if isinstance(labels_list, list): # Ensure it's a list before joining\n",
        "        labels = ', '.join(labels_list)\n",
        "    else: # If for some reason it's a string or other format, handle it\n",
        "        labels = str(labels_list) if labels_list is not None else ''\n",
        "\n",
        "\n",
        "    # Components and FixVersions often come as list of dictionaries, usually with a 'name' key\n",
        "    # Let's adjust them to be robust as well, similar to how we handled resolution\n",
        "    components_list = fields.get('components', [])\n",
        "    components = ', '.join([comp.get('name') for comp in components_list if isinstance(comp, dict) and comp.get('name')])\n",
        "\n",
        "    fix_versions_list = fields.get('fixVersions', [])\n",
        "    fix_versions = ', '.join([fv.get('name') for fv in fix_versions_list if isinstance(fv, dict) and fv.get('name')])\n",
        "    # --- FIX ENDS HERE ---\n",
        "\n",
        "    processed_issue_data.append({\n",
        "        'key': issue.get('key'),\n",
        "        'summary': fields.get('summary'),\n",
        "        'description': fields.get('description'),\n",
        "        'status': fields.get('status', {}).get('name'),\n",
        "        'resolution': resolution_name,\n",
        "        'issue_type': fields.get('issuetype', {}).get('name'),\n",
        "        'priority': fields.get('priority', {}).get('name'),\n",
        "        'creator': creator_name,\n",
        "        'assignee': assignee_name,\n",
        "        'created_at': fields.get('created'),\n",
        "        'updated_at': fields.get('updated'),\n",
        "        'resolved_at': fields.get('resolutiondate'),\n",
        "        'labels': labels, # Use the safely extracted labels\n",
        "        'components': components, # Use the safely extracted components\n",
        "        'fix_versions': fix_versions, # Use the safely extracted fix_versions\n",
        "        'comments_count': fields.get('comment', {}).get('total')\n",
        "    })\n",
        "\n",
        "# Ensure the output directory exists before saving\n",
        "output_dir = \"data/raw/\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir) # This will create 'data' and 'data/raw' if they don't exist\n",
        "    print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "# --- Save to Raw Data Folder ---\n",
        "df_raw = pd.DataFrame(processed_issue_data)\n",
        "output_path = os.path.join(output_dir, \"kafka_bug_reports_raw.csv\") # Use os.path.join for better path handling\n",
        "df_raw.to_csv(output_path, index=False)\n",
        "print(f\"Raw data saved to {output_path}\")\n",
        "\n",
        "# --- Initial EDA (Quick Check) ---\n",
        "print(\"\\n--- Initial Data Exploration ---\")\n",
        "print(df_raw.head())\n",
        "print(\"\\n--- Data Info ---\")\n",
        "print(df_raw.info())\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df_raw.isnull().sum())\n",
        "print(\"\\n--- Unique Issue Types (should be mostly 'Bug') ---\")\n",
        "print(df_raw['issue_type'].value_counts())\n",
        "print(\"\\n--- Unique Statuses ---\")\n",
        "print(df_raw['status'].value_counts())"
      ]
    }
  ]
}